---
title: "p8105_hw2_jy3186"
author: "Jiayi Yang"
date: "2022-10-02"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(dplyr)
library(lubridate)
```

## Problem 1 being addressed with answers
### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```


## Problem 2 
Mr. Trashwheel data cleaning
```{r, message=FALSE}
mrtrashwheel_df = read_excel("./Trash_data.xlsx", sheet = "Mr. Trash Wheel", range = ("A2:N550")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster)%>% 
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls),
         dumpster = as.integer(dumpster),
         year = as.integer(year),
         wheel_name = "Mr.trash")

```

Prof. Trashwheel data cleaning
```{r, message=FALSE}
proftrashwheel_df = read_excel("./Trash_data.xlsx", sheet = "Professor Trash Wheel", range = ("A2:M97")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
   mutate(sports_balls = 0,
     sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls),
         dumpster = as.integer(dumpster),
         wheel_name = "Prof.trash")
proftrashwheel_df
```
Now, combine Prof Trash Wheel with the Mr. Trash Wheel dataset to produce a single tidy dataset

```{r, message=FALSE}
combined = bind_rows(mrtrashwheel_df, proftrashwheel_df) %>% 
  janitor::clean_names() %>% 
  drop_na()
combined
```
To see the data of year 2020
```{r, message=FALSE}
mrtrashwheel_2020 = 
  mrtrashwheel_df %>% 
  filter(year ==  2020) %>% 
  drop_na()
```

## Description

The row size of the combined dataset is `r nrow(combined)`.

The column size of the combined dataset is `r ncol(combined)`.

Key variables are `Dumpster`	`Month`	`Year`	`Date`	`Weight (tons)`	`Volume (cubic yards)`	`Plastic Bottles`	`Polystyrene`	`Cigarette Butts`	`Glass Bottles`	`Grocery Bags`	`Chip Bags`	`Sports Balls`	`Homes Powered*`.

The total weight of trash collected by Professor Trash Wheel is `r sum(proftrashwheel_df $ weight_tons)`.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r sum(mrtrashwheel_2020 $ sports_balls)`.

---End of Problem 2---

## Problem 3

Importing and cleaning the dataset pols-month
```{r}
pols_month_df= 
  read_csv("./pols-month.csv") %>% 
  janitor::clean_names() %>% 
      separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(day = lubridate::mdy(day),
         year = as.integer(year),
         month = recode(month, "01" = "Jan", "02" = "Feb", "03" = "Mar",
                        "04" = "Apr", "05" = "May", "06" = "Jun", 
                        "07" = "Jul", "08" = "Aug", "09" = "Sep",
                        "10" = "Oct", "11" = "Nov", "12" = "Dec")
         ) %>% 
   mutate(
    president = ifelse(prez_dem == 0, "gop", "dem")) %>% 
    select(-prez_dem, -prez_gop, -day)

pols_month_df
```

Importing and cleaning the dataset snp
```{r}
snp_df =
  read_csv("./snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("day", "month", "year"), sep = "/") %>% 
  relocate( year, month, day) %>% 
    mutate(
           year = as.integer(year),
           day = lubridate::mdy(day),
           month = as.integer(month),
            month = recode(month, "01" = "Jan", "02" = "Feb", "03" = "Mar",
                        "04" = "Apr", "05" = "May", "06" = "Jun", 
                        "07" = "Jul", "08" = "Aug", "09" = "Sep",
                        "10" = "Oct", "11" = "Nov", "12" = "Dec"))
snp_df
```

Importing and cleaning unemployment data
```{r, message = FALSE}
unemployment_df =
  read_csv("./unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) 


unemployment_df
```

Join the datasets of snp and pols and then join unemployment into the result

```{r}
final_merged = 
  left_join(pols_month_df, snp_df) %>% 
   left_join(unemployment_df)
final_merged
```

## Description
There are three main datasets in problem 3, pols_month_df (pols) is the first step data we cleaned, spn_df (spn) is the second step data we cleaned, and unemployment_df is the third data we cleaned.
Then we merged two of the pol and spn data together and following by merging unemployment at the end. The final dataset is final_merged. 
It contains `r ncol(final_merged)` variables and `r nrow(final_merged)` observations.
There are two common variables `year` and `month`.
The range of years are from 1947 to 2015.
The names of key variables include: `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem` , `president`, `month`, `day`, `close`, and `unemployment_rate`.

